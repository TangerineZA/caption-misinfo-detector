{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911 = pd.read_csv('data_911.csv', index_col=0)\n",
    "df_chemtrails = pd.read_csv('data_chemtrails.csv', index_col=0)\n",
    "df_flatearth = pd.read_csv('data_flatearth.csv', index_col=0)\n",
    "df_moonlanding = pd.read_csv('data_moonlanding.csv', index_col=0)\n",
    "df_vaccines = pd.read_csv('data_vaccines.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911['normalized_annotation'] = df_911['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_chemtrails['normalized_annotation'] = df_chemtrails['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_flatearth['normalized_annotation'] = df_flatearth['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_moonlanding['normalized_annotation'] = df_moonlanding['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_vaccines['normalized_annotation'] = df_vaccines['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_annotation</th>\n",
       "      <th>Num_of_Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.004587</td>\n",
       "      <td>4.446220e+06</td>\n",
       "      <td>7.351247e+04</td>\n",
       "      <td>2931.933486</td>\n",
       "      <td>10780.392202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479441</td>\n",
       "      <td>9.546010e+06</td>\n",
       "      <td>1.923490e+05</td>\n",
       "      <td>6123.221874</td>\n",
       "      <td>29439.428059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.380000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.076780e+05</td>\n",
       "      <td>2.223500e+03</td>\n",
       "      <td>134.750000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.701835e+05</td>\n",
       "      <td>1.060350e+04</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>2214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.743950e+06</td>\n",
       "      <td>5.134300e+04</td>\n",
       "      <td>2976.250000</td>\n",
       "      <td>9600.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.386139e+08</td>\n",
       "      <td>1.902168e+06</td>\n",
       "      <td>69137.000000</td>\n",
       "      <td>393469.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized_annotation  Num_of_Views         Likes      Dislikes  \\\n",
       "count             436.000000  4.360000e+02  4.360000e+02    436.000000   \n",
       "mean               -0.004587  4.446220e+06  7.351247e+04   2931.933486   \n",
       "std                 0.479441  9.546010e+06  1.923490e+05   6123.221874   \n",
       "min                -1.000000  5.380000e+02  0.000000e+00      0.000000   \n",
       "25%                 0.000000  2.076780e+05  2.223500e+03    134.750000   \n",
       "50%                 0.000000  9.701835e+05  1.060350e+04    774.000000   \n",
       "75%                 0.000000  4.743950e+06  5.134300e+04   2976.250000   \n",
       "max                 1.000000  1.386139e+08  1.902168e+06  69137.000000   \n",
       "\n",
       "       Number_of_Comments  \n",
       "count          436.000000  \n",
       "mean         10780.392202  \n",
       "std          29439.428059  \n",
       "min              0.000000  \n",
       "25%            425.000000  \n",
       "50%           2214.000000  \n",
       "75%           9600.750000  \n",
       "max         393469.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_911.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911['normalized_annotation'] = df_911['normalized_annotation'] + 1\n",
    "df_chemtrails['normalized_annotation'] = df_chemtrails['normalized_annotation'] + 1\n",
    "df_flatearth['normalized_annotation'] = df_flatearth['normalized_annotation'] + 1\n",
    "df_moonlanding['normalized_annotation'] = df_moonlanding['normalized_annotation'] + 1\n",
    "df_vaccines['normalized_annotation'] = df_vaccines['normalized_annotation'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_annotation</th>\n",
       "      <th>Num_of_Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.995413</td>\n",
       "      <td>4.446220e+06</td>\n",
       "      <td>7.351247e+04</td>\n",
       "      <td>2931.933486</td>\n",
       "      <td>10780.392202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479441</td>\n",
       "      <td>9.546010e+06</td>\n",
       "      <td>1.923490e+05</td>\n",
       "      <td>6123.221874</td>\n",
       "      <td>29439.428059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.380000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.076780e+05</td>\n",
       "      <td>2.223500e+03</td>\n",
       "      <td>134.750000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.701835e+05</td>\n",
       "      <td>1.060350e+04</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>2214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.743950e+06</td>\n",
       "      <td>5.134300e+04</td>\n",
       "      <td>2976.250000</td>\n",
       "      <td>9600.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.386139e+08</td>\n",
       "      <td>1.902168e+06</td>\n",
       "      <td>69137.000000</td>\n",
       "      <td>393469.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized_annotation  Num_of_Views         Likes      Dislikes  \\\n",
       "count             436.000000  4.360000e+02  4.360000e+02    436.000000   \n",
       "mean                0.995413  4.446220e+06  7.351247e+04   2931.933486   \n",
       "std                 0.479441  9.546010e+06  1.923490e+05   6123.221874   \n",
       "min                 0.000000  5.380000e+02  0.000000e+00      0.000000   \n",
       "25%                 1.000000  2.076780e+05  2.223500e+03    134.750000   \n",
       "50%                 1.000000  9.701835e+05  1.060350e+04    774.000000   \n",
       "75%                 1.000000  4.743950e+06  5.134300e+04   2976.250000   \n",
       "max                 2.000000  1.386139e+08  1.902168e+06  69137.000000   \n",
       "\n",
       "       Number_of_Comments  \n",
       "count          436.000000  \n",
       "mean         10780.392202  \n",
       "std          29439.428059  \n",
       "min              0.000000  \n",
       "25%            425.000000  \n",
       "50%           2214.000000  \n",
       "75%           9600.750000  \n",
       "max         393469.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_911.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911['Captions'] = df_911['Captions'].astype('string')\n",
    "df_chemtrails['Captions'] = df_chemtrails['Captions'].astype('string')\n",
    "df_flatearth['Captions'] = df_flatearth['Captions'].astype('string')\n",
    "df_moonlanding['Captions'] = df_moonlanding['Captions'].astype('string')\n",
    "df_vaccines['Captions'] = df_vaccines['Captions'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Title</th>\n",
       "      <th>vid_url</th>\n",
       "      <th>normalized_annotation</th>\n",
       "      <th>Num_of_Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "      <th>Video_ID</th>\n",
       "      <th>Captions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>22 years ago, federal agents raided the Branch...</td>\n",
       "      <td>The Shadow of Waco | Retro Report | The New Yo...</td>\n",
       "      <td>https://www.youtube.com/watch?v=hOW9AjskoOo</td>\n",
       "      <td>1</td>\n",
       "      <td>596113</td>\n",
       "      <td>5478</td>\n",
       "      <td>420</td>\n",
       "      <td>1688</td>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>it happened outside Waco Texas a heavily armed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>:::VIEWER DISCRETION ADVISED::: Watch and list...</td>\n",
       "      <td>Former Abortionist Dr. Levatino Destroys Pro-C...</td>\n",
       "      <td>https://www.youtube.com/watch?v=dIRcw45n9RU</td>\n",
       "      <td>1</td>\n",
       "      <td>520316</td>\n",
       "      <td>15965</td>\n",
       "      <td>640</td>\n",
       "      <td>6828</td>\n",
       "      <td>dIRcw45n9RU</td>\n",
       "      <td>thanks for coming it's nice to see a good turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>An investigation of how Donald Trump defied ex...</td>\n",
       "      <td>Trump's Road to the White House (full film) | ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=SMwXKl0odq8</td>\n",
       "      <td>1</td>\n",
       "      <td>1543110</td>\n",
       "      <td>12403</td>\n",
       "      <td>1721</td>\n",
       "      <td>5919</td>\n",
       "      <td>SMwXKl0odq8</td>\n",
       "      <td>&gt;&gt; Tonight... &gt;&gt; I, Donald John Trump,\n",
       " do sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The F.B.I.'s greatest unsolved case!  Presente...</td>\n",
       "      <td>The Strange Disappearance of D.B. Cooper</td>\n",
       "      <td>https://www.youtube.com/watch?v=oHSehKtDyoI</td>\n",
       "      <td>1</td>\n",
       "      <td>12129914</td>\n",
       "      <td>207614</td>\n",
       "      <td>7949</td>\n",
       "      <td>20664</td>\n",
       "      <td>oHSehKtDyoI</td>\n",
       "      <td>- This week on Buzzfeed Unsolved, we discuss t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>▶︎ Shockingly Offensive Auditions Has Simon Co...</td>\n",
       "      <td>SHOCKINGLY OFFENSIVE AUDITIONS Have Simon Cowe...</td>\n",
       "      <td>https://www.youtube.com/watch?v=N9COy7O7K-U</td>\n",
       "      <td>1</td>\n",
       "      <td>9681212</td>\n",
       "      <td>91657</td>\n",
       "      <td>5576</td>\n",
       "      <td>18965</td>\n",
       "      <td>N9COy7O7K-U</td>\n",
       "      <td>I'm Mason noise I'm 22 and I'm from\n",
       " Birmingha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Conspiracy Theories - 9/11 Truth Movement part 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=MeHqsfgB2v8</td>\n",
       "      <td>1</td>\n",
       "      <td>288314</td>\n",
       "      <td>902</td>\n",
       "      <td>257</td>\n",
       "      <td>1049</td>\n",
       "      <td>MeHqsfgB2v8</td>\n",
       "      <td>the 911 truth movement is about the search for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Michael Shermer (Author, \"Skeptic\") joins Dave...</td>\n",
       "      <td>Conspiracy Theories with Michael Shermer</td>\n",
       "      <td>https://www.youtube.com/watch?v=eGGjCZbMh9Y</td>\n",
       "      <td>0</td>\n",
       "      <td>27250</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>433</td>\n",
       "      <td>eGGjCZbMh9Y</td>\n",
       "      <td>you do talk a lot about conspiracy theories an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The collapse of the three World Trade Center s...</td>\n",
       "      <td>9/11 - Evidence of Controlled Demolition of WT...</td>\n",
       "      <td>https://www.youtube.com/watch?v=PGchJ3b6hVE</td>\n",
       "      <td>2</td>\n",
       "      <td>7981</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>PGchJ3b6hVE</td>\n",
       "      <td>okay yeah a lot of a deal material case you co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The world has changed after September 11th. It...</td>\n",
       "      <td>9/11 False Flag</td>\n",
       "      <td>https://www.youtube.com/watch?v=zhnNy5EsebA</td>\n",
       "      <td>1</td>\n",
       "      <td>216109</td>\n",
       "      <td>1058</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>zhnNy5EsebA</td>\n",
       "      <td>In a war dies is the truth we always find no m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The collapse of the three World Trade Center s...</td>\n",
       "      <td>9/11 - Evidence of Controlled Demolition of WT...</td>\n",
       "      <td>https://www.youtube.com/watch?v=z9Vr1WbPF9I</td>\n",
       "      <td>2</td>\n",
       "      <td>77392</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>435</td>\n",
       "      <td>z9Vr1WbPF9I</td>\n",
       "      <td>please how are you thank you i'm very fine oka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description  \\\n",
       "Topic                                                      \n",
       "911    22 years ago, federal agents raided the Branch...   \n",
       "911    :::VIEWER DISCRETION ADVISED::: Watch and list...   \n",
       "911    An investigation of how Donald Trump defied ex...   \n",
       "911    The F.B.I.'s greatest unsolved case!  Presente...   \n",
       "911    ▶︎ Shockingly Offensive Auditions Has Simon Co...   \n",
       "...                                                  ...   \n",
       "911                                                  NaN   \n",
       "911    Michael Shermer (Author, \"Skeptic\") joins Dave...   \n",
       "911    The collapse of the three World Trade Center s...   \n",
       "911    The world has changed after September 11th. It...   \n",
       "911    The collapse of the three World Trade Center s...   \n",
       "\n",
       "                                                   Title  \\\n",
       "Topic                                                      \n",
       "911    The Shadow of Waco | Retro Report | The New Yo...   \n",
       "911    Former Abortionist Dr. Levatino Destroys Pro-C...   \n",
       "911    Trump's Road to the White House (full film) | ...   \n",
       "911             The Strange Disappearance of D.B. Cooper   \n",
       "911    SHOCKINGLY OFFENSIVE AUDITIONS Have Simon Cowe...   \n",
       "...                                                  ...   \n",
       "911     Conspiracy Theories - 9/11 Truth Movement part 1   \n",
       "911             Conspiracy Theories with Michael Shermer   \n",
       "911    9/11 - Evidence of Controlled Demolition of WT...   \n",
       "911                                      9/11 False Flag   \n",
       "911    9/11 - Evidence of Controlled Demolition of WT...   \n",
       "\n",
       "                                           vid_url  normalized_annotation  \\\n",
       "Topic                                                                       \n",
       "911    https://www.youtube.com/watch?v=hOW9AjskoOo                      1   \n",
       "911    https://www.youtube.com/watch?v=dIRcw45n9RU                      1   \n",
       "911    https://www.youtube.com/watch?v=SMwXKl0odq8                      1   \n",
       "911    https://www.youtube.com/watch?v=oHSehKtDyoI                      1   \n",
       "911    https://www.youtube.com/watch?v=N9COy7O7K-U                      1   \n",
       "...                                            ...                    ...   \n",
       "911    https://www.youtube.com/watch?v=MeHqsfgB2v8                      1   \n",
       "911    https://www.youtube.com/watch?v=eGGjCZbMh9Y                      0   \n",
       "911    https://www.youtube.com/watch?v=PGchJ3b6hVE                      2   \n",
       "911    https://www.youtube.com/watch?v=zhnNy5EsebA                      1   \n",
       "911    https://www.youtube.com/watch?v=z9Vr1WbPF9I                      2   \n",
       "\n",
       "       Num_of_Views   Likes  Dislikes  Number_of_Comments     Video_ID  \\\n",
       "Topic                                                                    \n",
       "911          596113    5478       420                1688  hOW9AjskoOo   \n",
       "911          520316   15965       640                6828  dIRcw45n9RU   \n",
       "911         1543110   12403      1721                5919  SMwXKl0odq8   \n",
       "911        12129914  207614      7949               20664  oHSehKtDyoI   \n",
       "911         9681212   91657      5576               18965  N9COy7O7K-U   \n",
       "...             ...     ...       ...                 ...          ...   \n",
       "911          288314     902       257                1049  MeHqsfgB2v8   \n",
       "911           27250     616       120                 433  eGGjCZbMh9Y   \n",
       "911            7981      52         3                  12  PGchJ3b6hVE   \n",
       "911          216109    1058        69                 281  zhnNy5EsebA   \n",
       "911           77392     309        54                 435  z9Vr1WbPF9I   \n",
       "\n",
       "                                                Captions  \n",
       "Topic                                                     \n",
       "911    it happened outside Waco Texas a heavily armed...  \n",
       "911    thanks for coming it's nice to see a good turn...  \n",
       "911    >> Tonight... >> I, Donald John Trump,\n",
       " do sol...  \n",
       "911    - This week on Buzzfeed Unsolved, we discuss t...  \n",
       "911    I'm Mason noise I'm 22 and I'm from\n",
       " Birmingha...  \n",
       "...                                                  ...  \n",
       "911    the 911 truth movement is about the search for...  \n",
       "911    you do talk a lot about conspiracy theories an...  \n",
       "911    okay yeah a lot of a deal material case you co...  \n",
       "911    In a war dies is the truth we always find no m...  \n",
       "911    please how are you thank you i'm very fine oka...  \n",
       "\n",
       "[436 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_911, X_test_911, y_train_911, y_test_911 = train_test_split(\n",
    "    df_911['Captions'], df_911['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "911    they were all innocent children a son a brothe...\n",
       "911    good day everyone and welcome to today's video...\n",
       "911    welcome to renegade Inc the talk show which al...\n",
       "911    warning what you are about to watch may make y...\n",
       "911    >> Tonight... >> I, Donald John Trump,\n",
       " do sol...\n",
       "                             ...                        \n",
       "911    THOUSANDS PAY POWERFUL TRIBUTE TO A 9/11 FIRST...\n",
       "911    the appeal of conspiracy theories according to...\n",
       "911    will hide each other a special 2004 spirit pas...\n",
       "911    us-iran tensions still continue on and since t...\n",
       "911    guys you dismiss a podcast wait no that's the ...\n",
       "Name: Captions, Length: 392, dtype: string"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", trainable=False)\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_911 = tf.keras.layers.Dropout(0.1)(outputs['sequence_output'])\n",
    "nn_911 = tf.keras.layers.LSTM(units=128)(nn_911)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_911 = tf.keras.layers.Dropout(0.1)(nn_911)\n",
    "# out = tf.keras.layers.Dense(units=3, activation='softmax')(l5)\n",
    "nn_911 = tf.keras.layers.Dense(units=3)(nn_911)\n",
    "out_911 = tf.keras.layers.Softmax()(nn_911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE OUTPUT LAYER AFTER ADJUSTING \n",
    "model_911 = tf.keras.Model(inputs = [text_input], outputs = [out_911])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_911.compile(\n",
    "    loss=loss,\n",
    "    metrics=['accuracy'],\n",
    "    optimizer='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 37s 3s/step - loss: 0.7669 - accuracy: 0.7301 - val_loss: 0.7425 - val_accuracy: 0.7250\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.6276 - accuracy: 0.7812 - val_loss: 0.7155 - val_accuracy: 0.7250\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 32s 3s/step - loss: 0.5234 - accuracy: 0.7898 - val_loss: 0.6028 - val_accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.3725 - accuracy: 0.8665 - val_loss: 0.6367 - val_accuracy: 0.7250\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.2687 - accuracy: 0.9062 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 31s 3s/step - loss: 0.1607 - accuracy: 0.9517 - val_loss: 0.6573 - val_accuracy: 0.7250\n"
     ]
    }
   ],
   "source": [
    "history = model_911.fit(X_train_911, y_train_911, epochs=50,  validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 902ms/step - loss: 0.8387 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8386572003364563, 0.75]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy was .94ish\n",
    "model_911.evaluate(X_test_911, y_test_911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_chemtrails, X_test_chemtrails, y_train_chemtrails, y_test_chemtrails = train_test_split(\n",
    "    df_chemtrails['Captions'], df_chemtrails['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_chemtrails = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_chemtrails = bert_preprocess(text_input_chemtrails)\n",
    "outputs_chemtrails = bert_encoder(preprocessed_text_chemtrails)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_ct = tf.keras.layers.Dropout(0.1)(outputs_chemtrails['sequence_output'])\n",
    "nn_ct = tf.keras.layers.LSTM(units=128)(nn_ct)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_ct = tf.keras.layers.Dropout(0.1)(nn_ct)\n",
    "nn_ct = tf.keras.layers.Dense(units=3)(nn_ct)\n",
    "out_ct = tf.keras.layers.Softmax()(nn_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chemtrails = tf.keras.Model(inputs = [text_input_chemtrails], outputs = [out_ct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chemtrails.compile(\n",
    "    loss=loss,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 38s 3s/step - loss: 0.9264 - accuracy: 0.5780 - val_loss: 0.7167 - val_accuracy: 0.6364\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.6569 - accuracy: 0.7391 - val_loss: 0.6591 - val_accuracy: 0.6591\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.5594 - accuracy: 0.7826 - val_loss: 0.8062 - val_accuracy: 0.6818\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.4742 - accuracy: 0.8031 - val_loss: 0.6472 - val_accuracy: 0.6591\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.3077 - accuracy: 0.8977 - val_loss: 0.6925 - val_accuracy: 0.7955\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.1881 - accuracy: 0.9335 - val_loss: 0.7243 - val_accuracy: 0.7727\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.1146 - accuracy: 0.9693 - val_loss: 1.2042 - val_accuracy: 0.7045\n"
     ]
    }
   ],
   "source": [
    "history_ct = model_chemtrails.fit(X_train_chemtrails, y_train_chemtrails, epochs=50, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 4s 1s/step - loss: 0.9690 - accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9689990282058716, 0.7142857313156128]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chemtrails.evaluate(X_test_chemtrails, y_test_chemtrails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7436542510986328, 0.767123281955719]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.7436542510986328, 0.767123281955719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_flatearth, X_test_flatearth, y_train_flatearth, y_test_flatearth = train_test_split(\n",
    "    df_flatearth['Captions'], df_flatearth['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_flatearth = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_flatearth = bert_preprocess(text_input_flatearth)\n",
    "outputs_flatearth = bert_encoder(preprocessed_text_flatearth)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_fe = tf.keras.layers.Dropout(0.1)(outputs_flatearth['sequence_output'])\n",
    "nn_fe = tf.keras.layers.LSTM(units=128)(nn_fe)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_fe = tf.keras.layers.Dropout(0.1)(nn_fe)\n",
    "nn_fe = tf.keras.layers.Dense(units=3)(nn_fe)\n",
    "out_fe = tf.keras.layers.Softmax()(nn_fe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fe = tf.keras.Model(inputs = [text_input_flatearth], outputs = [out_fe])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_fe.compile(\n",
    "    loss=loss,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 26s 3s/step - loss: 0.7783 - accuracy: 0.6914 - val_loss: 1.1511 - val_accuracy: 0.5862\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.6078 - accuracy: 0.7539 - val_loss: 1.0409 - val_accuracy: 0.5517\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 23s 3s/step - loss: 0.4929 - accuracy: 0.7930 - val_loss: 1.1137 - val_accuracy: 0.4828\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 22s 3s/step - loss: 0.3689 - accuracy: 0.8633 - val_loss: 1.4059 - val_accuracy: 0.4828\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 22s 3s/step - loss: 0.3875 - accuracy: 0.8359 - val_loss: 1.3742 - val_accuracy: 0.5172\n"
     ]
    }
   ],
   "source": [
    "history_fe = model_fe.fit(X_train_flatearth, y_train_flatearth, epochs=50,  validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.0536 - accuracy: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0536222457885742, 0.6875]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chemtrails.evaluate(X_test_flatearth, y_test_flatearth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "vaccines    oh here's some news tucker carlson can eat who...\n",
       "vaccines    how protective do we really need to be of our ...\n",
       "vaccines    You may not know it, but your body is engaged\n",
       "...\n",
       "vaccines    In the deserts of the American Southwest, spad...\n",
       "vaccines    who loves my new dog I got him today after my ...\n",
       "                                  ...                        \n",
       "vaccines    at this Minneapolis Medical Clinic signs in En...\n",
       "vaccines    >>> SHOULD PARENTS HAVE THEIR   \n",
       " CHILDREN VAC...\n",
       "vaccines    RECEIVE AND WHEN THEY SHOULD GET THEM.  >> Rep...\n",
       "vaccines    starting today kids in Oregon can be sent home...\n",
       "vaccines    (lively upbeat music) - The effectiveness of t...\n",
       "Name: Captions, Length: 621, dtype: string"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vaccines['Captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vc, X_test_vc, y_train_vc, y_test_vc = train_test_split(\n",
    "    df_vaccines['Captions'], df_vaccines['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_vc = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_vc = bert_preprocess(text_input_vc)\n",
    "outputs_vc = bert_encoder(preprocessed_text_vc)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_vc = tf.keras.layers.Dropout(0.1)(outputs_vc['sequence_output'])\n",
    "nn_vc = tf.keras.layers.LSTM(units=128)(nn_vc)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_vc = tf.keras.layers.Dropout(0.1)(nn_vc)\n",
    "nn_vc = tf.keras.layers.Dense(units=3)(nn_vc)\n",
    "out_vc = tf.keras.layers.Softmax()(nn_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vc = tf.keras.Model(inputs = [text_input_vc], outputs = [out_vc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vc.compile(\n",
    "    loss=loss,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.7198 - accuracy: 0.7191 - val_loss: 0.7399 - val_accuracy: 0.7143\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 44s 3s/step - loss: 0.5305 - accuracy: 0.7948 - val_loss: 0.6415 - val_accuracy: 0.7143\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 44s 3s/step - loss: 0.4281 - accuracy: 0.8426 - val_loss: 0.6798 - val_accuracy: 0.7679\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.2950 - accuracy: 0.8705 - val_loss: 0.6489 - val_accuracy: 0.7679\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 43s 3s/step - loss: 0.1741 - accuracy: 0.9482 - val_loss: 0.7623 - val_accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "history_vc = model_vc.fit(X_train_vc, y_train_vc, epochs=50,  validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO still make model with moonlanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat model\n",
    "\n",
    "input_cc = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "model_911_layer = model_911(input_cc)\n",
    "model_chemtrails_layer = model_chemtrails(input_cc)\n",
    "model_fe_layer = model_fe(input_cc)\n",
    "model_vc_layer = model_vc(input_cc)\n",
    "\n",
    "nn_cc = tf.keras.layers.Concatenate()([model_911_layer, model_chemtrails_layer, model_fe_layer, model_vc_layer])\n",
    "nn_cc = tf.keras.layers.Dense(units=3)(nn_cc)\n",
    "out_cc = tf.keras.layers.Softmax()(nn_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 3)            109941892   ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 3)            109941892   ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 3)            109941892   ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 3)            109941892   ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 12)           0           ['model[0][0]',                  \n",
      "                                                                  'model_1[0][0]',                \n",
      "                                                                  'model_2[0][0]',                \n",
      "                                                                  'model_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 3)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " softmax_4 (Softmax)            (None, 3)            0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111,320,884\n",
      "Trainable params: 1,838,643\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_concat = tf.keras.Model(inputs = [input_cc], outputs = [out_cc])\n",
    "model_concat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ten years after 9/11 a new report out just th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Music] it happened outside Waco Texas a heav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanks for coming it's nice to see a good tur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&amp;gt;&amp;gt; Tonight... &amp;gt;&amp;gt; I, Donald John T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- This week on Buzzfeed Unsolved, we discuss ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          annotation  stance\n",
       "0   ten years after 9/11 a new report out just th...       0\n",
       "1   [Music] it happened outside Waco Texas a heav...       0\n",
       "2   thanks for coming it's nice to see a good tur...       0\n",
       "3   &gt;&gt; Tonight... &gt;&gt; I, Donald John T...       0\n",
       "4   - This week on Buzzfeed Unsolved, we discuss ...       0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_csv('finished_df.csv', index_col=0)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['numerical_stance'] = df_combined['stance'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_combined['annotation'] = df_combined['annotation'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ten years after 9/11 a new report out just th...\n",
       "1        [Music] it happened outside Waco Texas a heav...\n",
       "2        thanks for coming it's nice to see a good tur...\n",
       "3        &gt;&gt; Tonight... &gt;&gt; I, Donald John T...\n",
       "4        - This week on Buzzfeed Unsolved, we discuss ...\n",
       "                              ...                        \n",
       "2667     dr. david groves is a physicist in the UK and...\n",
       "2668     - Hi, I'm Matt. And I don't believe we landed...\n",
       "2669                                                 <NA>\n",
       "2670     hi everybody what i'd like to talk about for ...\n",
       "2671     Apparently, there's an organization called \"N...\n",
       "Name: annotation, Length: 2672, dtype: string"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2667    2\n",
       "2668    2\n",
       "2669    0\n",
       "2670    1\n",
       "2671    0\n",
       "Name: stance, Length: 2672, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['stance'] = df_combined['stance'] + 1\n",
    "df_combined['stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cc, X_test_cc, y_train_cc, y_test_cc = train_test_split(\n",
    "    df_combined['annotation'], df_combined['stance'], test_size=0.15, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_concat.compile(\n",
    "    loss=loss,\n",
    "    optimizer='adam',\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "71/71 [==============================] - 614s 9s/step - loss: 0.7986 - accuracy: 0.7217\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 604s 9s/step - loss: 0.7477 - accuracy: 0.7429\n",
      "Epoch 3/50\n",
      "22/71 [========>.....................] - ETA: 6:59 - loss: 0.7073 - accuracy: 0.7571"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\tiktec\\yt-captions\\notebook_complete_dataset_merging.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/tiktec/yt-captions/notebook_complete_dataset_merging.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history_cc \u001b[39m=\u001b[39m model_concat\u001b[39m.\u001b[39;49mfit(X_train_cc,  y_train_cc, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\david\\anaconda3\\envs\\research-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_cc = model_concat.fit(X_train_cc,  y_train_cc, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
