{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 09:55:14.735060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 09:55:16.960875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:16.988817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:16.988927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911 = pd.read_csv('data_911.csv', index_col=0)\n",
    "df_chemtrails = pd.read_csv('data_chemtrails.csv', index_col=0)\n",
    "df_flatearth = pd.read_csv('data_flatearth.csv', index_col=0)\n",
    "df_moonlanding = pd.read_csv('data_moonlanding.csv', index_col=0)\n",
    "df_vaccines = pd.read_csv('data_vaccines.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911['normalized_annotation'] = df_911['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_chemtrails['normalized_annotation'] = df_chemtrails['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_flatearth['normalized_annotation'] = df_flatearth['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_moonlanding['normalized_annotation'] = df_moonlanding['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_vaccines['normalized_annotation'] = df_vaccines['normalized_annotation'].apply(pd.to_numeric, errors = 'coerce').fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_annotation</th>\n",
       "      <th>Num_of_Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.004587</td>\n",
       "      <td>4.446220e+06</td>\n",
       "      <td>7.351247e+04</td>\n",
       "      <td>2931.933486</td>\n",
       "      <td>10780.392202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479441</td>\n",
       "      <td>9.546010e+06</td>\n",
       "      <td>1.923490e+05</td>\n",
       "      <td>6123.221874</td>\n",
       "      <td>29439.428059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.380000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.076780e+05</td>\n",
       "      <td>2.223500e+03</td>\n",
       "      <td>134.750000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.701835e+05</td>\n",
       "      <td>1.060350e+04</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>2214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.743950e+06</td>\n",
       "      <td>5.134300e+04</td>\n",
       "      <td>2976.250000</td>\n",
       "      <td>9600.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.386139e+08</td>\n",
       "      <td>1.902168e+06</td>\n",
       "      <td>69137.000000</td>\n",
       "      <td>393469.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized_annotation  Num_of_Views         Likes      Dislikes  \\\n",
       "count             436.000000  4.360000e+02  4.360000e+02    436.000000   \n",
       "mean               -0.004587  4.446220e+06  7.351247e+04   2931.933486   \n",
       "std                 0.479441  9.546010e+06  1.923490e+05   6123.221874   \n",
       "min                -1.000000  5.380000e+02  0.000000e+00      0.000000   \n",
       "25%                 0.000000  2.076780e+05  2.223500e+03    134.750000   \n",
       "50%                 0.000000  9.701835e+05  1.060350e+04    774.000000   \n",
       "75%                 0.000000  4.743950e+06  5.134300e+04   2976.250000   \n",
       "max                 1.000000  1.386139e+08  1.902168e+06  69137.000000   \n",
       "\n",
       "       Number_of_Comments  \n",
       "count          436.000000  \n",
       "mean         10780.392202  \n",
       "std          29439.428059  \n",
       "min              0.000000  \n",
       "25%            425.000000  \n",
       "50%           2214.000000  \n",
       "75%           9600.750000  \n",
       "max         393469.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_911.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911['normalized_annotation'] = df_911['normalized_annotation'] + 1\n",
    "df_chemtrails['normalized_annotation'] = df_chemtrails['normalized_annotation'] + 1\n",
    "df_flatearth['normalized_annotation'] = df_flatearth['normalized_annotation'] + 1\n",
    "df_moonlanding['normalized_annotation'] = df_moonlanding['normalized_annotation'] + 1\n",
    "df_vaccines['normalized_annotation'] = df_vaccines['normalized_annotation'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_annotation</th>\n",
       "      <th>Num_of_Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>4.360000e+02</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.995413</td>\n",
       "      <td>4.446220e+06</td>\n",
       "      <td>7.351247e+04</td>\n",
       "      <td>2931.933486</td>\n",
       "      <td>10780.392202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479441</td>\n",
       "      <td>9.546010e+06</td>\n",
       "      <td>1.923490e+05</td>\n",
       "      <td>6123.221874</td>\n",
       "      <td>29439.428059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.380000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.076780e+05</td>\n",
       "      <td>2.223500e+03</td>\n",
       "      <td>134.750000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.701835e+05</td>\n",
       "      <td>1.060350e+04</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>2214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.743950e+06</td>\n",
       "      <td>5.134300e+04</td>\n",
       "      <td>2976.250000</td>\n",
       "      <td>9600.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.386139e+08</td>\n",
       "      <td>1.902168e+06</td>\n",
       "      <td>69137.000000</td>\n",
       "      <td>393469.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       normalized_annotation  Num_of_Views         Likes      Dislikes  \\\n",
       "count             436.000000  4.360000e+02  4.360000e+02    436.000000   \n",
       "mean                0.995413  4.446220e+06  7.351247e+04   2931.933486   \n",
       "std                 0.479441  9.546010e+06  1.923490e+05   6123.221874   \n",
       "min                 0.000000  5.380000e+02  0.000000e+00      0.000000   \n",
       "25%                 1.000000  2.076780e+05  2.223500e+03    134.750000   \n",
       "50%                 1.000000  9.701835e+05  1.060350e+04    774.000000   \n",
       "75%                 1.000000  4.743950e+06  5.134300e+04   2976.250000   \n",
       "max                 2.000000  1.386139e+08  1.902168e+06  69137.000000   \n",
       "\n",
       "       Number_of_Comments  \n",
       "count          436.000000  \n",
       "mean         10780.392202  \n",
       "std          29439.428059  \n",
       "min              0.000000  \n",
       "25%            425.000000  \n",
       "50%           2214.000000  \n",
       "75%           9600.750000  \n",
       "max         393469.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_911.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_911['Captions'] = df_911['Captions'].astype('string')\n",
    "df_chemtrails['Captions'] = df_chemtrails['Captions'].astype('string')\n",
    "df_flatearth['Captions'] = df_flatearth['Captions'].astype('string')\n",
    "df_moonlanding['Captions'] = df_moonlanding['Captions'].astype('string')\n",
    "df_vaccines['Captions'] = df_vaccines['Captions'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Title</th>\n",
       "      <th>vid_url</th>\n",
       "      <th>normalized_annotation</th>\n",
       "      <th>Num_of_Views</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "      <th>Video_ID</th>\n",
       "      <th>Captions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>22 years ago, federal agents raided the Branch...</td>\n",
       "      <td>The Shadow of Waco | Retro Report | The New Yo...</td>\n",
       "      <td>https://www.youtube.com/watch?v=hOW9AjskoOo</td>\n",
       "      <td>1</td>\n",
       "      <td>596113</td>\n",
       "      <td>5478</td>\n",
       "      <td>420</td>\n",
       "      <td>1688</td>\n",
       "      <td>hOW9AjskoOo</td>\n",
       "      <td>it happened outside Waco Texas a heavily armed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>:::VIEWER DISCRETION ADVISED::: Watch and list...</td>\n",
       "      <td>Former Abortionist Dr. Levatino Destroys Pro-C...</td>\n",
       "      <td>https://www.youtube.com/watch?v=dIRcw45n9RU</td>\n",
       "      <td>1</td>\n",
       "      <td>520316</td>\n",
       "      <td>15965</td>\n",
       "      <td>640</td>\n",
       "      <td>6828</td>\n",
       "      <td>dIRcw45n9RU</td>\n",
       "      <td>thanks for coming it's nice to see a good turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>An investigation of how Donald Trump defied ex...</td>\n",
       "      <td>Trump's Road to the White House (full film) | ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=SMwXKl0odq8</td>\n",
       "      <td>1</td>\n",
       "      <td>1543110</td>\n",
       "      <td>12403</td>\n",
       "      <td>1721</td>\n",
       "      <td>5919</td>\n",
       "      <td>SMwXKl0odq8</td>\n",
       "      <td>&gt;&gt; Tonight... &gt;&gt; I, Donald John Trump,\n",
       " do sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The F.B.I.'s greatest unsolved case!  Presente...</td>\n",
       "      <td>The Strange Disappearance of D.B. Cooper</td>\n",
       "      <td>https://www.youtube.com/watch?v=oHSehKtDyoI</td>\n",
       "      <td>1</td>\n",
       "      <td>12129914</td>\n",
       "      <td>207614</td>\n",
       "      <td>7949</td>\n",
       "      <td>20664</td>\n",
       "      <td>oHSehKtDyoI</td>\n",
       "      <td>- This week on Buzzfeed Unsolved, we discuss t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>▶︎ Shockingly Offensive Auditions Has Simon Co...</td>\n",
       "      <td>SHOCKINGLY OFFENSIVE AUDITIONS Have Simon Cowe...</td>\n",
       "      <td>https://www.youtube.com/watch?v=N9COy7O7K-U</td>\n",
       "      <td>1</td>\n",
       "      <td>9681212</td>\n",
       "      <td>91657</td>\n",
       "      <td>5576</td>\n",
       "      <td>18965</td>\n",
       "      <td>N9COy7O7K-U</td>\n",
       "      <td>I'm Mason noise I'm 22 and I'm from\n",
       " Birmingha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Conspiracy Theories - 9/11 Truth Movement part 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=MeHqsfgB2v8</td>\n",
       "      <td>1</td>\n",
       "      <td>288314</td>\n",
       "      <td>902</td>\n",
       "      <td>257</td>\n",
       "      <td>1049</td>\n",
       "      <td>MeHqsfgB2v8</td>\n",
       "      <td>the 911 truth movement is about the search for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Michael Shermer (Author, \"Skeptic\") joins Dave...</td>\n",
       "      <td>Conspiracy Theories with Michael Shermer</td>\n",
       "      <td>https://www.youtube.com/watch?v=eGGjCZbMh9Y</td>\n",
       "      <td>0</td>\n",
       "      <td>27250</td>\n",
       "      <td>616</td>\n",
       "      <td>120</td>\n",
       "      <td>433</td>\n",
       "      <td>eGGjCZbMh9Y</td>\n",
       "      <td>you do talk a lot about conspiracy theories an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The collapse of the three World Trade Center s...</td>\n",
       "      <td>9/11 - Evidence of Controlled Demolition of WT...</td>\n",
       "      <td>https://www.youtube.com/watch?v=PGchJ3b6hVE</td>\n",
       "      <td>2</td>\n",
       "      <td>7981</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>PGchJ3b6hVE</td>\n",
       "      <td>okay yeah a lot of a deal material case you co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The world has changed after September 11th. It...</td>\n",
       "      <td>9/11 False Flag</td>\n",
       "      <td>https://www.youtube.com/watch?v=zhnNy5EsebA</td>\n",
       "      <td>1</td>\n",
       "      <td>216109</td>\n",
       "      <td>1058</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>zhnNy5EsebA</td>\n",
       "      <td>In a war dies is the truth we always find no m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>The collapse of the three World Trade Center s...</td>\n",
       "      <td>9/11 - Evidence of Controlled Demolition of WT...</td>\n",
       "      <td>https://www.youtube.com/watch?v=z9Vr1WbPF9I</td>\n",
       "      <td>2</td>\n",
       "      <td>77392</td>\n",
       "      <td>309</td>\n",
       "      <td>54</td>\n",
       "      <td>435</td>\n",
       "      <td>z9Vr1WbPF9I</td>\n",
       "      <td>please how are you thank you i'm very fine oka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>436 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Description  \\\n",
       "Topic                                                      \n",
       "911    22 years ago, federal agents raided the Branch...   \n",
       "911    :::VIEWER DISCRETION ADVISED::: Watch and list...   \n",
       "911    An investigation of how Donald Trump defied ex...   \n",
       "911    The F.B.I.'s greatest unsolved case!  Presente...   \n",
       "911    ▶︎ Shockingly Offensive Auditions Has Simon Co...   \n",
       "...                                                  ...   \n",
       "911                                                  NaN   \n",
       "911    Michael Shermer (Author, \"Skeptic\") joins Dave...   \n",
       "911    The collapse of the three World Trade Center s...   \n",
       "911    The world has changed after September 11th. It...   \n",
       "911    The collapse of the three World Trade Center s...   \n",
       "\n",
       "                                                   Title  \\\n",
       "Topic                                                      \n",
       "911    The Shadow of Waco | Retro Report | The New Yo...   \n",
       "911    Former Abortionist Dr. Levatino Destroys Pro-C...   \n",
       "911    Trump's Road to the White House (full film) | ...   \n",
       "911             The Strange Disappearance of D.B. Cooper   \n",
       "911    SHOCKINGLY OFFENSIVE AUDITIONS Have Simon Cowe...   \n",
       "...                                                  ...   \n",
       "911     Conspiracy Theories - 9/11 Truth Movement part 1   \n",
       "911             Conspiracy Theories with Michael Shermer   \n",
       "911    9/11 - Evidence of Controlled Demolition of WT...   \n",
       "911                                      9/11 False Flag   \n",
       "911    9/11 - Evidence of Controlled Demolition of WT...   \n",
       "\n",
       "                                           vid_url  normalized_annotation  \\\n",
       "Topic                                                                       \n",
       "911    https://www.youtube.com/watch?v=hOW9AjskoOo                      1   \n",
       "911    https://www.youtube.com/watch?v=dIRcw45n9RU                      1   \n",
       "911    https://www.youtube.com/watch?v=SMwXKl0odq8                      1   \n",
       "911    https://www.youtube.com/watch?v=oHSehKtDyoI                      1   \n",
       "911    https://www.youtube.com/watch?v=N9COy7O7K-U                      1   \n",
       "...                                            ...                    ...   \n",
       "911    https://www.youtube.com/watch?v=MeHqsfgB2v8                      1   \n",
       "911    https://www.youtube.com/watch?v=eGGjCZbMh9Y                      0   \n",
       "911    https://www.youtube.com/watch?v=PGchJ3b6hVE                      2   \n",
       "911    https://www.youtube.com/watch?v=zhnNy5EsebA                      1   \n",
       "911    https://www.youtube.com/watch?v=z9Vr1WbPF9I                      2   \n",
       "\n",
       "       Num_of_Views   Likes  Dislikes  Number_of_Comments     Video_ID  \\\n",
       "Topic                                                                    \n",
       "911          596113    5478       420                1688  hOW9AjskoOo   \n",
       "911          520316   15965       640                6828  dIRcw45n9RU   \n",
       "911         1543110   12403      1721                5919  SMwXKl0odq8   \n",
       "911        12129914  207614      7949               20664  oHSehKtDyoI   \n",
       "911         9681212   91657      5576               18965  N9COy7O7K-U   \n",
       "...             ...     ...       ...                 ...          ...   \n",
       "911          288314     902       257                1049  MeHqsfgB2v8   \n",
       "911           27250     616       120                 433  eGGjCZbMh9Y   \n",
       "911            7981      52         3                  12  PGchJ3b6hVE   \n",
       "911          216109    1058        69                 281  zhnNy5EsebA   \n",
       "911           77392     309        54                 435  z9Vr1WbPF9I   \n",
       "\n",
       "                                                Captions  \n",
       "Topic                                                     \n",
       "911    it happened outside Waco Texas a heavily armed...  \n",
       "911    thanks for coming it's nice to see a good turn...  \n",
       "911    >> Tonight... >> I, Donald John Trump,\n",
       " do sol...  \n",
       "911    - This week on Buzzfeed Unsolved, we discuss t...  \n",
       "911    I'm Mason noise I'm 22 and I'm from\n",
       " Birmingha...  \n",
       "...                                                  ...  \n",
       "911    the 911 truth movement is about the search for...  \n",
       "911    you do talk a lot about conspiracy theories an...  \n",
       "911    okay yeah a lot of a deal material case you co...  \n",
       "911    In a war dies is the truth we always find no m...  \n",
       "911    please how are you thank you i'm very fine oka...  \n",
       "\n",
       "[436 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_911, X_test_911, y_train_911, y_test_911 = train_test_split(\n",
    "    df_911['Captions'], df_911['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "911    and I can go like this and I can do that on my...\n",
       "911    >>Female Presenter: Welcome everybody. It's\n",
       " g...\n",
       "911    This is Neverland, currently for sale, former ...\n",
       "911    the world is full of wild conspiracy theories ...\n",
       "911    DYLAN WELCH, REPORTER: Sydney grandmother\n",
       " Kar...\n",
       "                             ...                        \n",
       "911    MARSH IS JOINING US NOW WITH  MORE. WHAT'S THE...\n",
       "911    welcome back to football daily where today we ...\n",
       "911    9:11 magazine in wet mode the new 911 on an ex...\n",
       "911    you don't know already see Keith is a ticket a...\n",
       "911    all right how is it going today Lourdes my nam...\n",
       "Name: Captions, Length: 392, dtype: string"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 09:55:18.557719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:18.557919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:18.558025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:19.975367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:19.975490: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:19.975512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-09-27 09:55:19.975609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 09:55:19.975685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4577 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\", trainable=False)\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.legacy.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_911 = tf.keras.layers.Dropout(0.1)(outputs['sequence_output'])\n",
    "nn_911 = tf.keras.layers.LSTM(units=128)(nn_911)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_911 = tf.keras.layers.Dropout(0.1)(nn_911)\n",
    "# out = tf.keras.layers.Dense(units=3, activation='softmax')(l5)\n",
    "nn_911 = tf.keras.layers.Dense(units=3)(nn_911)\n",
    "out_911 = tf.keras.layers.Softmax()(nn_911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE OUTPUT LAYER AFTER ADJUSTING \n",
    "model_911 = tf.keras.Model(inputs = [text_input], outputs = [out_911])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_911.compile(\n",
    "    loss=loss,\n",
    "    metrics=['accuracy'],\n",
    "    optimizer=optim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 09:55:57.363035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 33s 1s/step - loss: 0.7118 - accuracy: 0.7602 - val_loss: 0.6673 - val_accuracy: 0.7955\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.5094 - accuracy: 0.7985 - val_loss: 0.6323 - val_accuracy: 0.7955\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.3572 - accuracy: 0.8571 - val_loss: 0.6892 - val_accuracy: 0.7955\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.2577 - accuracy: 0.8954 - val_loss: 0.7079 - val_accuracy: 0.7955\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.1487 - accuracy: 0.9668 - val_loss: 0.8034 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.0912 - accuracy: 0.9770 - val_loss: 0.8555 - val_accuracy: 0.7955\n"
     ]
    }
   ],
   "source": [
    "history = model_911.fit(X_train_911, y_train_911, epochs=50, callbacks=[early_stopping], validation_data=(X_test_911, y_test_911))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 341ms/step - loss: 0.8555 - accuracy: 0.7955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8555322289466858, 0.7954545617103577]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy was .94ish\n",
    "model_911.evaluate(X_test_911, y_test_911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_chemtrails, X_test_chemtrails, y_train_chemtrails, y_test_chemtrails = train_test_split(\n",
    "    df_chemtrails['Captions'], df_chemtrails['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_chemtrails = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_chemtrails = bert_preprocess(text_input_chemtrails)\n",
    "outputs_chemtrails = bert_encoder(preprocessed_text_chemtrails)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_ct = tf.keras.layers.Dropout(0.1)(outputs_chemtrails['sequence_output'])\n",
    "nn_ct = tf.keras.layers.LSTM(units=128)(nn_ct)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_ct = tf.keras.layers.Dropout(0.1)(nn_ct)\n",
    "nn_ct = tf.keras.layers.Dense(units=3)(nn_ct)\n",
    "out_ct = tf.keras.layers.Softmax()(nn_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chemtrails = tf.keras.Model(inputs = [text_input_chemtrails], outputs = [out_ct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chemtrails.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 25s 1s/step - loss: 0.8342 - accuracy: 0.6000 - val_loss: 0.8402 - val_accuracy: 0.6122\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.5751 - accuracy: 0.8046 - val_loss: 0.7530 - val_accuracy: 0.6531\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.4655 - accuracy: 0.8230 - val_loss: 0.8437 - val_accuracy: 0.6327\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.3111 - accuracy: 0.8851 - val_loss: 0.8660 - val_accuracy: 0.6939\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1395 - accuracy: 0.9609 - val_loss: 1.0259 - val_accuracy: 0.7347\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.0759 - accuracy: 0.9839 - val_loss: 1.0522 - val_accuracy: 0.6939\n"
     ]
    }
   ],
   "source": [
    "history_ct = model_chemtrails.fit(X_train_chemtrails, y_train_chemtrails, epochs=50, callbacks=[early_stopping], validation_data=(X_test_chemtrails, y_test_chemtrails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 471ms/step - loss: 1.0522 - accuracy: 0.6939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0522459745407104, 0.6938775777816772]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chemtrails.evaluate(X_test_chemtrails, y_test_chemtrails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7436542510986328, 0.767123281955719]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.7436542510986328, 0.767123281955719]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_flatearth, X_test_flatearth, y_train_flatearth, y_test_flatearth = train_test_split(\n",
    "    df_flatearth['Captions'], df_flatearth['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_flatearth = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_flatearth = bert_preprocess(text_input_flatearth)\n",
    "outputs_flatearth = bert_encoder(preprocessed_text_flatearth)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_fe = tf.keras.layers.Dropout(0.1)(outputs_flatearth['sequence_output'])\n",
    "nn_fe = tf.keras.layers.LSTM(units=128)(nn_fe)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_fe = tf.keras.layers.Dropout(0.1)(nn_fe)\n",
    "nn_fe = tf.keras.layers.Dense(units=3)(nn_fe)\n",
    "out_fe = tf.keras.layers.Softmax()(nn_fe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fe = tf.keras.Model(inputs = [text_input_flatearth], outputs = [out_fe])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_fe.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 21s 2s/step - loss: 0.8852 - accuracy: 0.6140 - val_loss: 0.7386 - val_accuracy: 0.7500\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6903 - accuracy: 0.7404 - val_loss: 0.6724 - val_accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.6002 - accuracy: 0.7439 - val_loss: 0.6494 - val_accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.4862 - accuracy: 0.8105 - val_loss: 0.7292 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.3810 - accuracy: 0.8526 - val_loss: 0.8052 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.2909 - accuracy: 0.8912 - val_loss: 0.8090 - val_accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 12s 1s/step - loss: 0.1800 - accuracy: 0.9333 - val_loss: 0.8678 - val_accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "history_fe = model_fe.fit(X_train_flatearth, y_train_flatearth, epochs=50, callbacks=[early_stopping], validation_data=(X_test_flatearth, y_test_flatearth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.2299 - accuracy: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2298762798309326, 0.71875]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_chemtrails.evaluate(X_test_flatearth, y_test_flatearth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic\n",
       "vaccines    oh here's some news tucker carlson can eat who...\n",
       "vaccines    how protective do we really need to be of our ...\n",
       "vaccines    You may not know it, but your body is engaged\n",
       "...\n",
       "vaccines    In the deserts of the American Southwest, spad...\n",
       "vaccines    who loves my new dog I got him today after my ...\n",
       "                                  ...                        \n",
       "vaccines    at this Minneapolis Medical Clinic signs in En...\n",
       "vaccines    >>> SHOULD PARENTS HAVE THEIR   \n",
       " CHILDREN VAC...\n",
       "vaccines    RECEIVE AND WHEN THEY SHOULD GET THEM.  >> Rep...\n",
       "vaccines    starting today kids in Oregon can be sent home...\n",
       "vaccines    (lively upbeat music) - The effectiveness of t...\n",
       "Name: Captions, Length: 621, dtype: string"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vaccines['Captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vc, X_test_vc, y_train_vc, y_test_vc = train_test_split(\n",
    "    df_vaccines['Captions'], df_vaccines['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_vc = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_vc = bert_preprocess(text_input_vc)\n",
    "outputs_vc = bert_encoder(preprocessed_text_vc)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_vc = tf.keras.layers.Dropout(0.1)(outputs_vc['sequence_output'])\n",
    "nn_vc = tf.keras.layers.LSTM(units=128)(nn_vc)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_vc = tf.keras.layers.Dropout(0.1)(nn_vc)\n",
    "nn_vc = tf.keras.layers.Dense(units=3)(nn_vc)\n",
    "out_vc = tf.keras.layers.Softmax()(nn_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vc = tf.keras.Model(inputs = [text_input_vc], outputs = [out_vc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vc.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 31s 1s/step - loss: 0.7563 - accuracy: 0.6918 - val_loss: 0.6440 - val_accuracy: 0.6825\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.5663 - accuracy: 0.7778 - val_loss: 0.5883 - val_accuracy: 0.7460\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.4310 - accuracy: 0.8387 - val_loss: 0.5713 - val_accuracy: 0.7937\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.2915 - accuracy: 0.8907 - val_loss: 0.6906 - val_accuracy: 0.7460\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.2049 - accuracy: 0.9337 - val_loss: 0.6513 - val_accuracy: 0.8095\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0895 - accuracy: 0.9767 - val_loss: 0.6961 - val_accuracy: 0.7619\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.0435 - accuracy: 0.9928 - val_loss: 0.7358 - val_accuracy: 0.7937\n"
     ]
    }
   ],
   "source": [
    "history_vc = model_vc.fit(X_train_vc, y_train_vc, epochs=50, callbacks=[early_stopping], validation_data=(X_test_vc, y_test_vc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO still make model with moonlanding\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
    "    df_moonlanding['Captions'], df_moonlanding['normalized_annotation'], test_size=0.1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert layers\n",
    "text_input_ml = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text_ml = bert_preprocess(text_input_ml)\n",
    "outputs_ml = bert_encoder(preprocessed_text_ml)\n",
    "\n",
    "# concat = tf.keras.layers.Concatenate()(outputs)\n",
    "\n",
    "# nn layers\n",
    "# l1 = tf.keras.layers.Dropout(0.1)(outputs['pooled_output'])\n",
    "nn_ml = tf.keras.layers.Dropout(0.1)(outputs_ml['sequence_output'])\n",
    "nn_ml = tf.keras.layers.LSTM(units=128)(nn_ml)\n",
    "# l4 = tf.keras.layers.LSTM(units=128)(l2)\n",
    "nn_ml = tf.keras.layers.Dropout(0.1)(nn_ml)\n",
    "nn_ml = tf.keras.layers.Dense(units=3)(nn_ml)\n",
    "out_ml = tf.keras.layers.Softmax()(nn_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ml = tf.keras.Model(inputs = [text_input_ml], outputs = [out_ml])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ml.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 18s 1s/step - loss: 0.9060 - accuracy: 0.6351 - val_loss: 0.6098 - val_accuracy: 0.8125\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.7022 - accuracy: 0.7053 - val_loss: 0.5719 - val_accuracy: 0.8125\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.6067 - accuracy: 0.7614 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.5242 - accuracy: 0.7895 - val_loss: 0.5572 - val_accuracy: 0.8125\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.4427 - accuracy: 0.8035 - val_loss: 0.6681 - val_accuracy: 0.7812\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.3217 - accuracy: 0.8596 - val_loss: 0.6161 - val_accuracy: 0.7812\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 10s 1s/step - loss: 0.2277 - accuracy: 0.9263 - val_loss: 0.6455 - val_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "history_ml = model_ml.fit(X_train_ml, y_train_ml, epochs=50, callbacks=[early_stopping], validation_data=(X_test_ml, y_test_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat model\n",
    "\n",
    "input_cc = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "model_911_layer = model_911(input_cc)\n",
    "model_chemtrails_layer = model_chemtrails(input_cc)\n",
    "model_fe_layer = model_fe(input_cc)\n",
    "model_vc_layer = model_vc(input_cc)\n",
    "model_ml_layer = model_ml(input_cc)\n",
    "\n",
    "nn_cc = tf.keras.layers.Concatenate()([model_911_layer, model_chemtrails_layer, model_fe_layer, model_vc_layer, model_ml_layer])\n",
    "nn_cc = tf.keras.layers.Dense(units=3)(nn_cc)\n",
    "out_cc = tf.keras.layers.Softmax()(nn_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None,)]                    0         []                            \n",
      "                                                                                                  \n",
      " model (Functional)          (None, 3)                    1099418   ['input_6[0][0]']             \n",
      "                                                          92                                      \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 3)                    1099418   ['input_6[0][0]']             \n",
      "                                                          92                                      \n",
      "                                                                                                  \n",
      " model_2 (Functional)        (None, 3)                    1099418   ['input_6[0][0]']             \n",
      "                                                          92                                      \n",
      "                                                                                                  \n",
      " model_3 (Functional)        (None, 3)                    1099418   ['input_6[0][0]']             \n",
      "                                                          92                                      \n",
      "                                                                                                  \n",
      " model_4 (Functional)        (None, 3)                    1099418   ['input_6[0][0]']             \n",
      "                                                          92                                      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 15)                   0         ['model[0][0]',               \n",
      "                                                                     'model_1[0][0]',             \n",
      "                                                                     'model_2[0][0]',             \n",
      "                                                                     'model_3[0][0]',             \n",
      "                                                                     'model_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 3)                    48        ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " softmax_5 (Softmax)         (None, 3)                    0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 111780544 (426.41 MB)\n",
      "Trainable params: 2298303 (8.77 MB)\n",
      "Non-trainable params: 109482241 (417.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_concat = tf.keras.Model(inputs = [input_cc], outputs = [out_cc])\n",
    "model_concat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>stance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ten years after 9/11 a new report out just th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Music] it happened outside Waco Texas a heav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thanks for coming it's nice to see a good tur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&amp;gt;&amp;gt; Tonight... &amp;gt;&amp;gt; I, Donald John T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- This week on Buzzfeed Unsolved, we discuss ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          annotation  stance\n",
       "0   ten years after 9/11 a new report out just th...       0\n",
       "1   [Music] it happened outside Waco Texas a heav...       0\n",
       "2   thanks for coming it's nice to see a good tur...       0\n",
       "3   &gt;&gt; Tonight... &gt;&gt; I, Donald John T...       0\n",
       "4   - This week on Buzzfeed Unsolved, we discuss ...       0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.read_csv('finished_df.csv', index_col=0)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['numerical_stance'] = df_combined['stance'].apply(pd.to_numeric, errors = 'coerce').fillna(1)\n",
    "df_combined['annotation'] = df_combined['annotation'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ten years after 9/11 a new report out just th...\n",
       "1        [Music] it happened outside Waco Texas a heav...\n",
       "2        thanks for coming it's nice to see a good tur...\n",
       "3        &gt;&gt; Tonight... &gt;&gt; I, Donald John T...\n",
       "4        - This week on Buzzfeed Unsolved, we discuss ...\n",
       "                              ...                        \n",
       "2667     dr. david groves is a physicist in the UK and...\n",
       "2668     - Hi, I'm Matt. And I don't believe we landed...\n",
       "2669                                                 <NA>\n",
       "2670     hi everybody what i'd like to talk about for ...\n",
       "2671     Apparently, there's an organization called \"N...\n",
       "Name: annotation, Length: 2672, dtype: string"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "2667    2\n",
       "2668    2\n",
       "2669    0\n",
       "2670    1\n",
       "2671    0\n",
       "Name: stance, Length: 2672, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['stance'] = df_combined['stance'] + 1\n",
    "df_combined['stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cc, X_test_cc, y_train_cc, y_test_cc = train_test_split(\n",
    "    df_combined['annotation'], df_combined['stance'], test_size=0.15, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_concat.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optim,\n",
    "    metrics='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 372s 5s/step - loss: 0.7380 - accuracy: 0.7390 - val_loss: 0.6988 - val_accuracy: 0.7350\n",
      "Epoch 2/50\n",
      "71/71 [==============================] - 342s 5s/step - loss: 0.6251 - accuracy: 0.7540 - val_loss: 0.6236 - val_accuracy: 0.7525\n",
      "Epoch 3/50\n",
      "71/71 [==============================] - 342s 5s/step - loss: 0.5551 - accuracy: 0.7787 - val_loss: 0.6346 - val_accuracy: 0.7625\n",
      "Epoch 4/50\n",
      "71/71 [==============================] - 348s 5s/step - loss: 0.4951 - accuracy: 0.8118 - val_loss: 0.5474 - val_accuracy: 0.7900\n",
      "Epoch 5/50\n",
      "71/71 [==============================] - 340s 5s/step - loss: 0.4303 - accuracy: 0.8405 - val_loss: 0.4996 - val_accuracy: 0.8125\n",
      "Epoch 6/50\n",
      "71/71 [==============================] - 342s 5s/step - loss: 0.3361 - accuracy: 0.8962 - val_loss: 0.4824 - val_accuracy: 0.8225\n",
      "Epoch 7/50\n",
      "71/71 [==============================] - 341s 5s/step - loss: 0.2807 - accuracy: 0.9117 - val_loss: 0.4451 - val_accuracy: 0.8425\n",
      "Epoch 8/50\n",
      "71/71 [==============================] - 349s 5s/step - loss: 0.2291 - accuracy: 0.9377 - val_loss: 0.4513 - val_accuracy: 0.8400\n",
      "Epoch 9/50\n",
      "71/71 [==============================] - 341s 5s/step - loss: 0.1744 - accuracy: 0.9589 - val_loss: 0.4636 - val_accuracy: 0.8400\n",
      "Epoch 10/50\n",
      "71/71 [==============================] - 341s 5s/step - loss: 0.1399 - accuracy: 0.9708 - val_loss: 0.4488 - val_accuracy: 0.8325\n",
      "Epoch 11/50\n",
      "71/71 [==============================] - 341s 5s/step - loss: 0.1155 - accuracy: 0.9801 - val_loss: 0.4547 - val_accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "history_cc = model_concat.fit(X_train_cc,  y_train_cc, epochs=50, callbacks=[early_stopping], validation_data=(X_test_cc, y_test_cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_complete_withml/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_complete_withml/assets\n"
     ]
    }
   ],
   "source": [
    "# model_concat.save('trained_complete_withml', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(history_cc.history).to_csv('history_complete_withml.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
